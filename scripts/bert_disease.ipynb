{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66gRmRDMBbUC",
        "outputId": "a4867c9c-6f4d-441e-cdc6-9c309ada9ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIZ7-W_4GS65",
        "outputId": "fc48c018-8f8a-4774-951c-442da655242e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 18 02:44:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D5Oz_7IaGc24"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "import sys\n",
        "from transformers import BertTokenizer,BertModel\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ag2Hl1hGGh6e"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/text_dataonly.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SxnmUyzdGy6O"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14W2MTZ1Ij5F",
        "outputId": "d252207e-5b32-4416-cf74-7b560077b906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HFZI10YEH1xk"
      },
      "outputs": [],
      "source": [
        "encoded_labels = pd.get_dummies(df['label'], prefix='label')\n",
        "df = pd.concat([df['text'], encoded_labels], axis=1)\n",
        "df.columns = ['text'] + list(encoded_labels.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ14SOaaIWZ2",
        "outputId": "f6479c1a-af73-40d0-9f02-264c3abdf217"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2171, 13)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Qoxiq4iHuYK"
      },
      "outputs": [],
      "source": [
        "target = encoded_labels.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yfCEIJinI6io"
      },
      "outputs": [],
      "source": [
        "#hyperparams\n",
        "max_len = 256\n",
        "train_batch_size=32\n",
        "val_batch_size=32\n",
        "epochs=8\n",
        "lr = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHY1H2OgI7dM",
        "outputId": "e4d1f298-2496-4082-b8cd-d74210250140"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lA6iyhviJbnq"
      },
      "outputs": [],
      "source": [
        "class diseaseDataset(torch.utils.data.Dataset):\n",
        "  #constructor\n",
        "  def __init__(self, df, tokenizer, max_len):\n",
        "    self.df=df\n",
        "    self.tokenizer=tokenizer\n",
        "    self.max_len=max_len\n",
        "    self.title = self.df[\"text\"]\n",
        "    self.targets = self.df[target].values\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.title)\n",
        "\n",
        "  #so no garabge\n",
        "  def __getitem__(self,index):\n",
        "    title = str(self.title[index])\n",
        "    title = \" \".join(title.split())\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "        title,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len,\n",
        "        padding=\"max_length\",\n",
        "        return_token_type_ids=True,\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return {\n",
        "      'input_ids': inputs['input_ids'].flatten(),\n",
        "      'attention_mask': inputs['attention_mask'].flatten(),\n",
        "      'token_type_ids':inputs['token_type_ids'].flatten(),\n",
        "      'targets':torch.FloatTensor(self.targets[index])\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G8bUoI4rT_54"
      },
      "outputs": [],
      "source": [
        "train_df, test_df= train_test_split(df,test_size=0.1,random_state=2)\n",
        "train_df=train_df.reset_index(drop=True)\n",
        "test_df=test_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZiKU3bdij-w",
        "outputId": "c9ab2d14-8dff-49ce-dbc0-ab91131880cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2171"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og7zl2B1ioX0",
        "outputId": "9307e516-5475-4db1-952a-53c7eec823fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "218"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH4kkciBifiq",
        "outputId": "ff2d5021-21b8-4afa-c00a-24849eaef95e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1953"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AbMc4VGSkgYC"
      },
      "outputs": [],
      "source": [
        "train_df, val_df= train_test_split(train_df,test_size=0.2,random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SU_02mmLlo9M"
      },
      "outputs": [],
      "source": [
        "train_df=train_df.reset_index(drop=True)\n",
        "val_df=val_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "XDu7jRf5K8So"
      },
      "outputs": [],
      "source": [
        "# train_size = 0.8\n",
        "# train_df = train_df.sample(frac=train_size, random_state=2).reset_index(drop=True)\n",
        "# # train_df = train_df.sample(n=1550, random_state=2).reset_index(drop=True)\n",
        "# val_df = train_df.drop(train_df.index).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0td-NKliFUb",
        "outputId": "f524d819-8306-4106-d323-6a26fd036f78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "391"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ClO9XCdZK9gk"
      },
      "outputs": [],
      "source": [
        "train_dataset = diseaseDataset(train_df, tokenizer, max_len)\n",
        "val_dataset = diseaseDataset(val_df, tokenizer, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQYoc3-XhoLH",
        "outputId": "3b0e52c2-25bc-4953-ca88-3cef16021b01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "391"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "opzREOlBWN6a"
      },
      "outputs": [],
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=train_batch_size,\n",
        "    num_workers=0\n",
        ")\n",
        "val_data_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=val_batch_size,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YhXIAU2hkZd",
        "outputId": "12431dea-8773-4f21-9153-3749dea11782"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e0hGjiL8YH1z"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JGDAlYI1Y0D0"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
        "    path = checkpoint_path\n",
        "    torch.save(state, path)\n",
        "    if is_best:\n",
        "        best_path = best_model_path\n",
        "        shutil.copyfile(path, best_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtvSB2cZZBY2",
        "outputId": "f0005d33-bac2-4f4c-d540-00252356c7af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True) #1st layer\n",
        "        self.dropout = torch.nn.Dropout(0.1) #dropout layer\n",
        "        self.linear = torch.nn.Linear(768, 12) #bert_op = 768 layers\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2nwypk03aqJJ"
      },
      "outputs": [],
      "source": [
        "def loss_func(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params= model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "C3KdMfNCbBNu"
      },
      "outputs": [],
      "source": [
        "def train_model(n_epochs, train_loader, val_loader, model, opt, ckp_path, best_path):\n",
        "  val_loss_min= np.Inf\n",
        "  for epoch in range(1,epochs+1):\n",
        "    train_loss=0\n",
        "    val_loss=0\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "      ip_ids=batch[\"input_ids\"].to(device, dtype=torch.long)\n",
        "      attention_mask=batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
        "      token_type_ids=batch[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "      targets = batch[\"targets\"].to(device, dtype=torch.float)\n",
        "      op = model(ip_ids, attention_mask, token_type_ids)\n",
        "      opt.zero_grad()\n",
        "      loss = loss_func(op, targets)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      train_loss=train_loss+((1/(idx+1))*(loss.item()-train_loss))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(val_loader,0):\n",
        "        ip_ids=batch[\"input_ids\"].to(device, dtype=torch.long)\n",
        "        attention_mask=batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
        "        token_type_ids=batch[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "        targets = batch[\"targets\"].to(device, dtype=torch.float)\n",
        "        op = model(ip_ids, attention_mask, token_type_ids)\n",
        "        loss = loss_func(op, targets)\n",
        "        val_loss=val_loss+((1/(idx+1))*(loss.item()-val_loss))\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      val_loss = val_loss/len(val_loader)\n",
        "      # print training/validation statistics\n",
        "      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss,val_loss))\n",
        "      checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': val_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "      save_checkpoint(checkpoint, False, ckp_path, best_path)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS9T97-EfeOe",
        "outputId": "ef510c09-aeae-4356-ba58-2023700c8df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tAvgerage Training Loss: 0.010363 \tAverage Validation Loss: 0.006883\n",
            "Epoch: 2 \tAvgerage Training Loss: 0.006880 \tAverage Validation Loss: 0.005307\n",
            "Epoch: 3 \tAvgerage Training Loss: 0.005841 \tAverage Validation Loss: 0.004683\n",
            "Epoch: 4 \tAvgerage Training Loss: 0.005198 \tAverage Validation Loss: 0.004123\n",
            "Epoch: 5 \tAvgerage Training Loss: 0.004554 \tAverage Validation Loss: 0.003413\n",
            "Epoch: 6 \tAvgerage Training Loss: 0.003914 \tAverage Validation Loss: 0.002947\n",
            "Epoch: 7 \tAvgerage Training Loss: 0.003350 \tAverage Validation Loss: 0.002551\n",
            "Epoch: 8 \tAvgerage Training Loss: 0.002886 \tAverage Validation Loss: 0.002186\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(epochs, train_data_loader, val_data_loader,model,optimizer,\"/current_ckpt\",\"/best_ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkRLZJrhf9BD",
        "outputId": "d86d10f3-5c15-49e8-aef3-611e079e6617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label_Arthritis\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-599b3233af09>:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n"
          ]
        }
      ],
      "source": [
        "example = test_df['text'][0]\n",
        "encodings = tokenizer.encode_plus(\n",
        "    example,\n",
        "    None,\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    padding='max_length',\n",
        "    return_token_type_ids=True,\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n",
        "    attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n",
        "    token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n",
        "    output = model(input_ids, attention_mask, token_type_ids)\n",
        "    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n",
        "    print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "ZziAxfnehHjX",
        "outputId": "c46a3d0b-9060-4afc-960a-8900cf60ddcc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"My neck has been so tense, and I've been feeling like my muscles are incredibly weak. I have trouble moving since my joints have enlarged. To walk has been quite painful.\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4FTls8VtZdE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
